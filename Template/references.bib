@article{Liang2018,
author = {Liang, Deng and Wang, Yueqing and Liu, Yang and Wang, Fang and Li, Sikun and Liu, Jie},
year = {2018},
month = {10},
pages = {},
title = {A CNN-based vortex identification method},
volume = {22},
journal = {Journal of Visualization},
doi = {10.1007/s12650-018-0523-1}
}

ï»¿@Article{Wang2021,
author={Wang, Yueqing
and Deng, Liang
and Yang, Zhigong
and Zhao, Dan
and Wang, Fang},
title={A rapid vortex identification method using fully convolutional segmentation network},
journal={The Visual Computer},
year={2021},
month={Feb},
day={01},
volume={37},
number={2},
pages={261-273},
abstract={Vortex identification methods have been extensively studied in recent years due to their importance in understanding the potential physical mechanism of the flow field. Although demonstrating great success in various scenarios, these methods cannot achieve a compromise between computational speed and accuracy, which restricts their usage in large-scale applications. In specific, local methods provide results rapidly with pool accuracies. By contrast, global methods can obtain reliable results by consuming much more time. To take the advantages of both local and global methods, several methods based on convolutional neural networks are proposed. These methods use local patches around each point and the labels obtained by global methods to train the network. They convert the vortex identification tasks into binary classification problems. In this manner, these methods detect vortices rapidly and robustly. By revisiting these methods, we observe two drawbacks that limit their performance: (i) the large number of parameters and (ii) high computational complexity. To address these issues, we provide a rapid vortex identification method by using a fully convolutional segmentation network in this work. Specifically, we discard the fully connected layers to decrease the number of parameters and design a segmentation network to reduce computational complexity. Intensive experimental results show that the accuracy and recall performance of our method are comparable with those of the global methods. Moreover, the time consumption of our method is less than that of all other methods.},
issn={1432-2315},
doi={10.1007/s00371-020-01797-6},
url={https://doi.org/10.1007/s00371-020-01797-6}
}
@article{lu2021learning,
  title   = {Learning nonlinear operators via {DeepONet} based on the universal approximation theorem of operators},
  author  = {Lu, Lu and Jin, Pengzhan and Pang, Guofei and Zhang, Zhongqiang and Karniadakis, George Em},
  journal = {Nature Machine Intelligence},
  volume  = {3},
  number  = {3},
  pages   = {218--229},
  year    = {2021}
}